<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Computational Genomics With R" />
<meta property="og:type" content="book" />
<meta property="og:url" content="https://compmgenomr.github.io/book/" />
<meta property="og:image" content="https://compmgenomr.github.io/book/images/cover.jpg" />
<meta property="og:description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience" />
<meta name="github-repo" content="rstudio/bookdown" />

<meta name="author" content="Altuna Akalin" />

<meta name="date" content="2019-01-22" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A guide to computationa genomics using R. The book covers fundemental topics with practical examples for an interdisciplinery audience">

<title>Computational Genomics With R</title>

<script src="libs/jquery/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap/js/bootstrap.min.js"></script>
<script src="libs/bootstrap/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap/shim/respond.min.js"></script>
<script src="libs/navigation/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#preface">Preface</a><ul>
<li class="has-sub"><a href="who-is-this-book-for.html#who-is-this-book-for">Who is this book for?</a><ul>
<li><a href="who-is-this-book-for.html#what-will-you-get-out-of-this">What will you get out of this?</a></li>
</ul></li>
<li><a href="structure-of-the-book.html#structure-of-the-book">Structure of the book</a></li>
<li><a href="software-information-and-conventions.html#software-information-and-conventions">Software information and conventions</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
</ul></li>
<li><a href="1-how-to-contribute.html#how-to-contribute"><span class="toc-section-number">1</span> How to contribute</a></li>
<li><a href="about-the-authors.html#about-the-authors">About the Authors</a></li>
<li class="has-sub"><a href="2-intro.html#intro"><span class="toc-section-number">2</span> Introduction to Genomics</a><ul>
<li class="has-sub"><a href="2-1-genes-dna-and-central-dogma.html#genes-dna-and-central-dogma"><span class="toc-section-number">2.1</span> Genes, DNA and central dogma</a><ul>
<li><a href="2-1-genes-dna-and-central-dogma.html#what-is-a-genome"><span class="toc-section-number">2.1.1</span> What is a genome?</a></li>
<li><a href="2-1-genes-dna-and-central-dogma.html#what-is-a-gene"><span class="toc-section-number">2.1.2</span> What is a gene?</a></li>
<li><a href="2-1-genes-dna-and-central-dogma.html#how-genes-are-controlled-the-transcriptional-and-the-post-transcriptional-regulation"><span class="toc-section-number">2.1.3</span> How genes are controlled ? The transcriptional and the post-transcriptional regulation</a></li>
<li><a href="2-1-genes-dna-and-central-dogma.html#what-does-a-gene-look-like"><span class="toc-section-number">2.1.4</span> What does a gene look like?</a></li>
</ul></li>
<li class="has-sub"><a href="2-2-elements-of-gene-regulation.html#elements-of-gene-regulation"><span class="toc-section-number">2.2</span> Elements of gene regulation</a><ul>
<li><a href="2-2-elements-of-gene-regulation.html#transcriptional-regulation"><span class="toc-section-number">2.2.1</span> Transcriptional regulation</a></li>
<li><a href="2-2-elements-of-gene-regulation.html#post-transcriptional-regulation"><span class="toc-section-number">2.2.2</span> Post-transcriptional regulation</a></li>
</ul></li>
<li><a href="2-3-shaping-the-genome-dna-mutation.html#shaping-the-genome-dna-mutation"><span class="toc-section-number">2.3</span> Shaping the genome: DNA mutation</a></li>
<li class="has-sub"><a href="2-4-high-throughput-experimental-methods-in-genomics.html#high-throughput-experimental-methods-in-genomics"><span class="toc-section-number">2.4</span> High-throughput experimental methods in genomics</a><ul>
<li><a href="2-4-high-throughput-experimental-methods-in-genomics.html#the-general-idea-behind-high-throughput-techniques"><span class="toc-section-number">2.4.1</span> The general idea behind high-throughput techniques</a></li>
<li><a href="2-4-high-throughput-experimental-methods-in-genomics.html#high-throughput-sequencing"><span class="toc-section-number">2.4.2</span> High-throughput sequencing</a></li>
</ul></li>
<li><a href="2-5-visualization-and-data-repositories-for-genomics.html#visualization-and-data-repositories-for-genomics"><span class="toc-section-number">2.5</span> Visualization and data repositories for genomics</a></li>
</ul></li>
<li class="has-sub"><a href="3-Rintro.html#Rintro"><span class="toc-section-number">3</span> Introduction to R for genomic data analysis</a><ul>
<li class="has-sub"><a href="3-1-steps-of-genomic-data-analysis.html#steps-of-genomic-data-analysis"><span class="toc-section-number">3.1</span> Steps of (genomic) data analysis</a><ul>
<li><a href="3-1-steps-of-genomic-data-analysis.html#data-collection"><span class="toc-section-number">3.1.1</span> Data collection</a></li>
<li><a href="3-1-steps-of-genomic-data-analysis.html#data-quality-check-and-cleaning"><span class="toc-section-number">3.1.2</span> Data quality check and cleaning</a></li>
<li><a href="3-1-steps-of-genomic-data-analysis.html#data-processing"><span class="toc-section-number">3.1.3</span> Data processing</a></li>
<li><a href="3-1-steps-of-genomic-data-analysis.html#exploratory-data-analysis-and-modeling"><span class="toc-section-number">3.1.4</span> Exploratory data analysis and modeling</a></li>
<li><a href="3-1-steps-of-genomic-data-analysis.html#visualization-and-reporting"><span class="toc-section-number">3.1.5</span> Visualization and reporting</a></li>
<li><a href="3-1-steps-of-genomic-data-analysis.html#why-use-r-for-genomics"><span class="toc-section-number">3.1.6</span> Why use R for genomics ?</a></li>
</ul></li>
<li class="has-sub"><a href="3-2-getting-started-with-r.html#getting-started-with-r"><span class="toc-section-number">3.2</span> Getting started with R</a><ul>
<li><a href="3-2-getting-started-with-r.html#installing-packages"><span class="toc-section-number">3.2.1</span> Installing packages</a></li>
<li><a href="3-2-getting-started-with-r.html#installing-packages-in-custom-locations"><span class="toc-section-number">3.2.2</span> Installing packages in custom locations</a></li>
<li><a href="3-2-getting-started-with-r.html#getting-help-on-functions-and-packages"><span class="toc-section-number">3.2.3</span> Getting help on functions and packages</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-stats.html#stats"><span class="toc-section-number">4</span> Statistics and Exploratory Data Analysis for Genomics</a><ul>
<li class="has-sub"><a href="4-1-how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions"><span class="toc-section-number">4.1</span> How to summarize collection of data points: The idea behind statistical distributions</a><ul>
<li><a href="4-1-how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#describing-the-central-tendency-mean-and-median"><span class="toc-section-number">4.1.1</span> Describing the central tendency: mean and median</a></li>
<li><a href="4-1-how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#describing-the-spread-measurements-of-variation"><span class="toc-section-number">4.1.2</span> Describing the spread: measurements of variation</a></li>
<li><a href="4-1-how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions.html#precision-of-estimates-confidence-intervals"><span class="toc-section-number">4.1.3</span> Precision of estimates: Confidence intervals</a></li>
</ul></li>
<li class="has-sub"><a href="4-2-how-to-test-for-differences-between-samples.html#how-to-test-for-differences-between-samples"><span class="toc-section-number">4.2</span> How to test for differences between samples</a><ul>
<li><a href="4-2-how-to-test-for-differences-between-samples.html#randomization-based-testing-for-difference-of-the-means"><span class="toc-section-number">4.2.1</span> randomization based testing for difference of the means</a></li>
<li><a href="4-2-how-to-test-for-differences-between-samples.html#using-t-test-for-difference-of-the-means-between-two-samples"><span class="toc-section-number">4.2.2</span> Using t-test for difference of the means between two samples</a></li>
<li><a href="4-2-how-to-test-for-differences-between-samples.html#multiple-testing-correction"><span class="toc-section-number">4.2.3</span> multiple testing correction</a></li>
<li><a href="4-2-how-to-test-for-differences-between-samples.html#moderated-t-tests-using-information-from-multiple-comparisons"><span class="toc-section-number">4.2.4</span> moderated t-tests: using information from multiple comparisons</a></li>
</ul></li>
<li class="has-sub"><a href="4-3-relationship-between-variables-linear-models-and-correlation.html#relationship-between-variables-linear-models-and-correlation"><span class="toc-section-number">4.3</span> Relationship between variables: linear models and correlation</a><ul>
<li><a href="4-3-relationship-between-variables-linear-models-and-correlation.html#how-to-fit-a-line"><span class="toc-section-number">4.3.1</span> How to fit a line</a></li>
<li><a href="4-3-relationship-between-variables-linear-models-and-correlation.html#how-to-estimate-the-error-of-the-coefficients"><span class="toc-section-number">4.3.2</span> How to estimate the error of the coefficients</a></li>
<li><a href="4-3-relationship-between-variables-linear-models-and-correlation.html#accuracy-of-the-model"><span class="toc-section-number">4.3.3</span> Accuracy of the model</a></li>
<li><a href="4-3-relationship-between-variables-linear-models-and-correlation.html#regression-with-categorical-variables"><span class="toc-section-number">4.3.4</span> Regression with categorical variables</a></li>
<li><a href="4-3-relationship-between-variables-linear-models-and-correlation.html#regression-pitfalls"><span class="toc-section-number">4.3.5</span> Regression pitfalls</a></li>
</ul></li>
<li class="has-sub"><a href="4-4-clustering-grouping-samples-based-on-their-similarity.html#clustering-grouping-samples-based-on-their-similarity"><span class="toc-section-number">4.4</span> Clustering: grouping samples based on their similarity</a><ul>
<li><a href="4-4-clustering-grouping-samples-based-on-their-similarity.html#distance-metrics"><span class="toc-section-number">4.4.1</span> Distance metrics</a></li>
<li><a href="4-4-clustering-grouping-samples-based-on-their-similarity.html#hiearchical-clustering"><span class="toc-section-number">4.4.2</span> Hiearchical clustering</a></li>
<li><a href="4-4-clustering-grouping-samples-based-on-their-similarity.html#k-means-clustering"><span class="toc-section-number">4.4.3</span> K-means clustering</a></li>
<li><a href="4-4-clustering-grouping-samples-based-on-their-similarity.html#how-to-choose-k-the-number-of-clusters"><span class="toc-section-number">4.4.4</span> how to choose “k”, the number of clusters</a></li>
</ul></li>
<li class="has-sub"><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d"><span class="toc-section-number">4.5</span> Dimensionality reduction techniques: visualizing complex data sets in 2D</a><ul>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#principal-component-analysis"><span class="toc-section-number">4.5.1</span> Principal component analysis</a></li>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#other-dimension-reduction-techniques-using-other-matrix-factorization-methods"><span class="toc-section-number">4.5.2</span> Other dimension reduction techniques using other matrix factorization methods</a></li>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#multi-dimensional-scaling"><span class="toc-section-number">4.5.3</span> Multi-dimensional scaling</a></li>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#t-distributed-stochastic-neighbor-embedding-t-sne"><span class="toc-section-number">4.5.4</span> t-Distributed Stochastic Neighbor Embedding (t-SNE)</a></li>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions-1"><span class="toc-section-number">4.5.5</span> How to summarize collection of data points: The idea behind statistical distributions</a></li>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#how-to-test-for-differences-in-samples"><span class="toc-section-number">4.5.6</span> How to test for differences in samples</a></li>
<li><a href="4-5-dimensionality-reduction-techniques-visualizing-complex-data-sets-in-2d.html#relationship-between-variables-linear-models-and-correlation-1"><span class="toc-section-number">4.5.7</span> Relationship between variables: linear models and correlation</a></li>
</ul></li>
</ul></li>
<li><a href="5-genomicIntervals.html#genomicIntervals"><span class="toc-section-number">5</span> Operations on Genomic Intervals and Genome Arithmetic</a></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="how-to-summarize-collection-of-data-points-the-idea-behind-statistical-distributions" class="section level2">
<h2><span class="header-section-number">4.1</span> How to summarize collection of data points: The idea behind statistical distributions</h2>
<p>In biology and many other fields data is collected via experimentation.
The nature of the experiments and natural variation in biology makes
it impossible to get the same exact measurements every time you measure something.
For example, if you are measuring gene expression values for
a certain gene, say PAX6, and let’s assume you are measuring expression
per sample and cell with any method( microarrays, rt-qPCR, etc.). You will not
get the same expression value even if your samples are homogeneous. Due
to technical bias in experiments or natural variation in the samples. Instead,
we would like to describe this collection of data some other way
that represents the general properties of the data. The figure shows a sample of
20 expression values from PAX6 gene.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-8"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-8-1.png" alt="Expression of PAX6 gene in 20 replicate experiments" width="60%" />
<p class="caption">
FIGURE 4.1: Expression of PAX6 gene in 20 replicate experiments
</p>
</div>
<div id="describing-the-central-tendency-mean-and-median" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Describing the central tendency: mean and median</h3>
<p>As seen in the figure above, the points from this sample are distributed around
a central value and the histogram below the dot plot shows number of points in
each bin. Another observation is that there are some bins that have more points than others. If we want to summarize what we observe, we can try
to represent the collection of data points
with an expression value that is typical to get, something that represents the
general tendency we observe on the dot plot and the histogram. This value is
sometimes called central
value or central tendency, and there are different ways to calculate such a value.
In the figure above, we see that all the values are spread around 6.13 (red line),
and that is indeed what we call mean value of this sample of expression values.
It can be calculated with the following formula <span class="math inline">\(\overline{X}=\sum_{i=1}^n x_i/n\)</span>,
where <span class="math inline">\(x_i\)</span> is the expression value of an experiment and <span class="math inline">\(n\)</span> is the number of
expression value obtained from the experiments. In R, <code>mean()</code> function will calculate the
mean of a provided vector of numbers. This is called a “sample mean”. In reality
the possible values of PAX6 expression for all cells (provided each cell is of the
identical cell type and is in identical conditions) are much much more than 20.
If we had the time and the funding to sample all cells and measure PAX6 expression we would
get a collection values that would be called, in statistics, a “population”. In
our case the population will look like the left hand side of the figure below. What we have done with
our 20 data points is that we took a sample of PAX6 expression values from this
population, and calculated the sample mean.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-9"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-9-1.png" alt="Expression of all possible PAX6 gene expressions measures on all available biological samples (left). Expression of PAX6 gene from statistical sample, a random subset, from the population of biological samples (Right). " width="75%" />
<p class="caption">
FIGURE 4.2: Expression of all possible PAX6 gene expressions measures on all available biological samples (left). Expression of PAX6 gene from statistical sample, a random subset, from the population of biological samples (Right).
</p>
</div>
<p>The mean of the population is calculated the same way but traditionally
Greek letter <span class="math inline">\(\mu\)</span> is used to denote the population mean. Normally, we would not
have access to the population and we will use sample mean and other quantities
derived from the sample to estimate the population properties. This is the basic
idea behind statistical inference which we will see this in action in later
sections as well. We
estimate the population parameters from the sample parameters and there is some
uncertainty associated with those estimates. We will be trying to assess those
uncertainties and make decisions in the presence of those uncertainties.</p>
<p>We are not yet done with measuring central tendency.
There are other ways to describe it, such as the median value.
Mean can be affected by outliers easily.
If certain values are very high or low from the
bulk of the sample this will shift mean towards those outliers. However, median
is not affected by outliers. It is simply the value in a distribution where half
of the values are above and the other half is below. In R, <code>median()</code> function
will calculate the mean of a provided vector of numbers.</p>
<p>Let’s create a set of random numbers and calculate their mean and median using
R.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="co">#create 10 random numbers from uniform distribution </span></a>
<a class="sourceLine" id="cb8-2" title="2">x=<span class="kw">runif</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb8-3" title="3"><span class="co"># calculate mean</span></a>
<a class="sourceLine" id="cb8-4" title="4"><span class="kw">mean</span>(x)</a></code></pre></div>
<pre><code>## [1] 0.3739</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="co"># calculate median</span></a>
<a class="sourceLine" id="cb10-2" title="2"><span class="kw">median</span>(x)</a></code></pre></div>
<pre><code>## [1] 0.3278</code></pre>
</div>
<div id="describing-the-spread-measurements-of-variation" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Describing the spread: measurements of variation</h3>
<p>Another useful way to summarize a collection of data points is to measure
how variable the values are. You can simply describe the range of the values
, such as minimum and maximum values. You can easily do that in R with <code>range()</code>
function. A more common way to calculate variation is by calculating something
called “standard deviation” or the related quantity called “variance”. This is a
quantity that shows how variable the values are, a value around zero indicates
there is not much variation in the values of the data points, and a high value
indicates high variation in the values. The variance is the squared distance of
data points from the mean. Population variance is again a quantity we usually
do not have access to and is simply calculate as follows <span class="math inline">\(\sigma^2=\sum_{i=1}^n \frac{(x_i-\mu)^2}{n}\)</span>, where <span class="math inline">\(\mu\)</span> is the population mean, <span class="math inline">\(x_i\)</span> is the ith
data point in the population and <span class="math inline">\(n\)</span> is the population size. However, when the
we have only access to a sample this formulation is biased. It means that it
underestimates the population variance, so we make a small adjustment when we
calculate the sample variance, denoted as <span class="math inline">\(s^2\)</span>:
<span class="math display">\[
\begin{aligned}
s^2=\sum_{i=1}^n \frac{(x_i-\overline{X})^2}{n-1} &amp;&amp; \text{ where $x_i$ is the ith data point and
$\overline{X}$ is the sample mean.}
\end{aligned}
\]</span></p>
<p>The sample standard deviation is simply the square-root of the sample variance.
The good thing about standard deviation is that it has the same unit as the mean
so it is more intuitive.<br />
<span class="math display">\[s=\sqrt{\sum_{i=1}^n \frac{(x_i-\overline{X})^2}{n-1}}\]</span></p>
<p>We can calculate sample standard deviation and variation with <code>sd()</code> and <code>var()</code>
functions in R. These functions take vector of numeric values as input and
calculate the desired quantities. Below we use those functions on a randomly
generated vector of numbers.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1">x=<span class="kw">rnorm</span>(<span class="dv">20</span>,<span class="dt">mean=</span><span class="dv">6</span>,<span class="dt">sd=</span><span class="fl">0.7</span>)</a>
<a class="sourceLine" id="cb12-2" title="2"><span class="kw">var</span>(x)</a></code></pre></div>
<pre><code>## [1] 0.2531</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1"><span class="kw">sd</span>(x)</a></code></pre></div>
<pre><code>## [1] 0.5031</code></pre>
<p>One potential problem with the variance is that it could be affected by
outliers. The points that are too far away from the mean will have a large
affect on the variance even though there might be few of them.
A way to measure variance that could be less affected by outliers is
looking at where bulk of the distribution is. How do we define where the bulk is?
One common way is to look at the the difference between 75th percentile and 25th
percentile, this effectively removes a lot of potential outliers which will be
towards the edges of the range of values.
This is called interquartile range , and
can be easily calculated using R via <code>IQR()</code> function and the quantiles of a vector
is calculated with <code>quantile()</code> function.</p>
<p>Let us plot the boxplot for a random vector and also calculate IQR using R.
In the boxplot below, 25th and 75th percentiles are the edges of the box, and
the median is marked with a thick line going through roughly middle the box.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1">x=<span class="kw">rnorm</span>(<span class="dv">20</span>,<span class="dt">mean=</span><span class="dv">6</span>,<span class="dt">sd=</span><span class="fl">0.7</span>)</a>
<a class="sourceLine" id="cb16-2" title="2"><span class="kw">IQR</span>(x)</a></code></pre></div>
<pre><code>## [1] 0.5011</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1"><span class="kw">quantile</span>(x)</a></code></pre></div>
<pre><code>##    0%   25%   50%   75%  100% 
## 5.437 5.743 5.860 6.244 6.558</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="kw">boxplot</span>(x,<span class="dt">horizontal =</span> T)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-14"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-14-1.png" alt="Boxplot showing 25th percentile and 75th percentile and median for a set of points sample from a normal distribution with mean=6 and standard deviation=0.7" width="60%" />
<p class="caption">
FIGURE 4.3: Boxplot showing 25th percentile and 75th percentile and median for a set of points sample from a normal distribution with mean=6 and standard deviation=0.7
</p>
</div>
<div id="frequently-used-statistical-distributions" class="section level4">
<h4><span class="header-section-number">4.1.2.1</span> Frequently used statistical distributions</h4>
<p>The distributions have parameters (such as mean and variance) that
summarizes them but also they are functions that assigns each outcome of a
statistical experiment to its probability of occurrence.
One distribution that you
will frequently encounter is the normal distribution or Gaussian distribution.
The normal distribution has a typical “bell-curve” shape
and, characterized by mean and standard deviation. A set of data points
that
follow normal distribution mostly will be close to the mean
but spread around it controlled by the standard deviation parameter. That
means if we sample data points from a normal distribution we are more
likely to sample nearby the mean and sometimes away from the mean.
Probability of an event occurring is higher if it is nearby the mean.
The effect
of the parameters for normal distribution can be observed in the following
plot.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-15"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-15-1.png" alt="Different parameters for normal distribution and effect of those on the shape of the distribution" width="60%" />
<p class="caption">
FIGURE 4.4: Different parameters for normal distribution and effect of those on the shape of the distribution
</p>
</div>
<p>The normal distribution is often denoted by <span class="math inline">\(\mathcal{N}(\mu,\,\sigma^2)\)</span> When a random variable <span class="math inline">\(X\)</span> is distributed normally with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, we write:</p>
<p><span class="math display">\[X\ \sim\ \mathcal{N}(\mu,\,\sigma^2).\]</span></p>
<p>The probability
density function of Normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation
<span class="math inline">\(\sigma\)</span> is as follows</p>
<p><span class="math display">\[P(x)=\frac{1}{\sigma\sqrt{2\pi} } \; e^{ -\frac{(x-\mu)^2}{2\sigma^2} } \]</span></p>
<p>The probability density function gives the probability of observing a value
on a normal distribution defined by <span class="math inline">\(\mu\)</span> and
<span class="math inline">\(\sigma\)</span> parameters.</p>
<p>Often times, we do not need the exact probability of a value but we need the
probability of observing a value larger or smaller than a critical value or reference
point. For example, we might want to know the probability of <span class="math inline">\(X\)</span> being smaller than or
equal to -2 for a normal distribution with mean 0 and standard deviation 2.
,<span class="math inline">\(P(X &lt;= -2 \; | \; \mu=0,\sigma=2)\)</span>. In this case, what we want is the are under the
curve shaded in blue. To be able to that we need to integrate the probability
density function but we will usually let software do that. Traditionally,
one calculates a Z-score which is simply <span class="math inline">\((X-\mu)/\sigma=(-2-0)/2= -1\)</span>, and
corresponds to how many standard deviations you are away from the mean.
This is also called “standardization”, the corresponding value is distributed in “standard normal distribution” where <span class="math inline">\(\mathcal{N}(0,\,1)\)</span>.</p>
<p>After calculating the Z-score,
we can go look up in a table, that contains the area under the curve for
the left and right side of the Z-score, but again we use software for that
tables are outdated.</p>
<p>Below we are showing the Z-score and the associated probabilities derived
from the calculation above for <span class="math inline">\(P(X &lt;= -2 \; | \; \mu=0,\sigma=2)\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:zscore"></span>
<img src="compgenomrReloaded_files/figure-html/zscore-1.png" alt="Z-score and associated probabilities for Z= -1" width="60%" />
<p class="caption">
FIGURE 4.5: Z-score and associated probabilities for Z= -1
</p>
</div>
<p>In R, family of <code>*norm</code> functions (<code>rnorm</code>,<code>dnorm</code>,<code>qnorm</code> and <code>pnorm</code>) can
be used to
operate with normal distribution, such as calculating probabilities and
generating random numbers drawn from normal distribution.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1"><span class="co"># get the probability of P(X= -2) where mean=0 and sd=2</span></a>
<a class="sourceLine" id="cb21-2" title="2"><span class="kw">dnorm</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.121</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1"><span class="co"># get the probability of P(X =&lt; -2) where mean=0 and sd=2</span></a>
<a class="sourceLine" id="cb23-2" title="2"><span class="kw">pnorm</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.1587</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1"><span class="co"># get the probability of P(X &gt; -2) where mean=0 and sd=2</span></a>
<a class="sourceLine" id="cb25-2" title="2"><span class="kw">pnorm</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">2</span>,<span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 0.8413</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1"><span class="co"># get 5 random numbers from normal dist with  mean=0 and sd=2</span></a>
<a class="sourceLine" id="cb27-2" title="2"><span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dt">mean=</span><span class="dv">0</span> , <span class="dt">sd=</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] -1.8109 -1.9221 -0.5147  0.8217 -0.7901</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1"><span class="co"># get y value corresponding to P(X &gt; y) = 0.15 with  mean=0 and sd=2</span></a>
<a class="sourceLine" id="cb29-2" title="2"><span class="kw">qnorm</span>( <span class="fl">0.15</span>, <span class="dt">mean=</span><span class="dv">0</span> , <span class="dt">sd=</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] -2.073</code></pre>
<p>There are many other distribution functions in R that can be used the same
way. You have to enter the distribution specific parameters along
with your critical value, quantiles or number of random numbers depending
on which function you are using in the family.We will list some of those functions below.</p>
<ul>
<li><p><code>dbinom</code> is for binomial distribution. This distribution is usually used
to model fractional data and binary data. Examples from genomics includes
methylation data.</p></li>
<li><p><code>dpois</code> is used for Poisson distribution and <code>dnbinom</code> is used for
negative binomial distribution. These distributions are used to model count
data such as sequencing read counts.</p></li>
<li><p><code>df</code> (F distribution) and <code>dchisq</code> (Chi-Squared distribution) are used
in relation to distribution of variation. F distribution is used to model
ratios of variation and Chi-Squared distribution is used to model
distribution of variations. You will frequently encounter these in linear models and generalized linear models.</p></li>
</ul>
</div>
</div>
<div id="precision-of-estimates-confidence-intervals" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Precision of estimates: Confidence intervals</h3>
<p>When we take a random sample from a population and compute a statistic, such as
the mean, we are trying to approximate the mean of the population. How well this
sample statistic estimates the population value will always be a
concern. A confidence interval addresses this concern because it provides a
range of values which is plausible to contain the population parameter of interest.
Normally, we would not have access to a population. If we did, we would not have to estimate the population parameters and its precision.</p>
<p>When we do not have access
to the population, one way to estimate intervals is to repeatedly take samples from the
original sample with replacement, that is we take a data point from the sample
we replace, and we take another data point until we have sample size of the
original sample. Then, we calculate the parameter of interest, in this case mean, and
repeat this step a large number of times, such as 1000. At this point, we would have a distribution of re-sampled
means, we can then calculate the 2.5th and 97.5th percentiles and these will
be our so-called 95% confidence interval. This procedure, resampling with replacement to
estimate the precision of population parameter estimates, is known as the <strong>bootstrap</strong>.</p>
<p>Let’s see how we can do this in practice. We simulate a sample
coming from a normal distribution (but we pretend we don’t know the
population parameters). We will try to estimate the precision
of the mean of the sample using bootstrap to build confidence intervals.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="kw">set.seed</span>(<span class="dv">21</span>)</a>
<a class="sourceLine" id="cb31-2" title="2">sample1=<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">50</span>,<span class="dv">20</span>,<span class="dv">5</span>) <span class="co"># simulate a sample</span></a>
<a class="sourceLine" id="cb31-3" title="3"></a>
<a class="sourceLine" id="cb31-4" title="4"><span class="co"># do bootstrap resampling, sampling with replacement</span></a>
<a class="sourceLine" id="cb31-5" title="5">boot.means=<span class="kw">do</span>(<span class="dv">1000</span>) <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">resample</span>(sample1))</a>
<a class="sourceLine" id="cb31-6" title="6"></a>
<a class="sourceLine" id="cb31-7" title="7"><span class="co"># get percentiles from the bootstrap means</span></a>
<a class="sourceLine" id="cb31-8" title="8">q=<span class="kw">quantile</span>(boot.means[,<span class="dv">1</span>],<span class="dt">p=</span><span class="kw">c</span>(<span class="fl">0.025</span>,<span class="fl">0.975</span>))</a>
<a class="sourceLine" id="cb31-9" title="9"></a>
<a class="sourceLine" id="cb31-10" title="10"><span class="co"># plot the histogram</span></a>
<a class="sourceLine" id="cb31-11" title="11"><span class="kw">hist</span>(boot.means[,<span class="dv">1</span>],<span class="dt">col=</span><span class="st">&quot;cornflowerblue&quot;</span>,<span class="dt">border=</span><span class="st">&quot;white&quot;</span>,</a>
<a class="sourceLine" id="cb31-12" title="12">                    <span class="dt">xlab=</span><span class="st">&quot;sample means&quot;</span>)</a>
<a class="sourceLine" id="cb31-13" title="13"><span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">c</span>(q[<span class="dv">1</span>], q[<span class="dv">2</span>] ),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb31-14" title="14"><span class="kw">text</span>(<span class="dt">x=</span>q[<span class="dv">1</span>],<span class="dt">y=</span><span class="dv">200</span>,<span class="kw">round</span>(q[<span class="dv">1</span>],<span class="dv">3</span>),<span class="dt">adj=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>))</a>
<a class="sourceLine" id="cb31-15" title="15"><span class="kw">text</span>(<span class="dt">x=</span>q[<span class="dv">2</span>],<span class="dt">y=</span><span class="dv">200</span>,<span class="kw">round</span>(q[<span class="dv">2</span>],<span class="dv">3</span>),<span class="dt">adj=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-17-1.png" alt="Precision estimate of the sample mean using 1000 bootstrap samples. Confidence intervals derived from the bootstrap samples are shown with red lines." width="70%" />
<p class="caption">
FIGURE 4.6: Precision estimate of the sample mean using 1000 bootstrap samples. Confidence intervals derived from the bootstrap samples are shown with red lines.
</p>
</div>
<p>If we had a convenient mathematical method to calculate confidence interval
we could also do without resampling methods. It turns out that if we take
repeated
samples from a population of with sample size <span class="math inline">\(n\)</span>, the distribution of means
( <span class="math inline">\(\overline{X}\)</span>) of those samples
will be approximately normal with mean <span class="math inline">\(\mu\)</span> and standard deviation
<span class="math inline">\(\sigma/\sqrt{n}\)</span>. This is also known as <strong>Central Limit Theorem(CLT)</strong> and
is one of the most important theorems in statistics. This also means that
<span class="math inline">\(\frac{\overline{X}-\mu}{\sigma\sqrt{n}}\)</span> has a standard normal
distribution and we can calculate the Z-score and then we can get
the percentiles associated with the Z-score. Below, we are showing the
Z-score
calculation for the distribution of <span class="math inline">\(\overline{X}\)</span>, and then
we are deriving the confidence intervals starting with the fact that
probability of Z being between -1.96 and 1.96 is 0.95. We then use algebra
to show that the probability that unknown <span class="math inline">\(\mu\)</span> is captured between
<span class="math inline">\(\overline{X}-1.96\sigma/\sqrt{n}\)</span> and <span class="math inline">\(\overline{X}+1.96\sigma/\sqrt{n}\)</span> is 0.95, which is commonly known as 95% confidence interval.</p>
<p><span class="math display">\[\begin{array}{ccc}
Z=\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\\
P(-1.96 &lt; Z &lt; 1.96)=0.95 \\
P(-1.96 &lt; \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} &lt; 1.96)=0.95\\
P(\mu-1.96\sigma/\sqrt{n} &lt; \overline{X} &lt; \mu+1.96\sigma/\sqrt{n})=0.95\\
P(\overline{X}-1.96\sigma/\sqrt{n} &lt; \mu &lt; \overline{X}+1.96\sigma/\sqrt{n})=0.95\\
confint=[\overline{X}-1.96\sigma/\sqrt{n},\overline{X}+1.96\sigma/\sqrt{n}]
\end{array}\]</span></p>
<p>A 95% confidence interval for population mean is the most common
common interval to use, and would
mean that we would expect 95% of the interval estimates to include the
population parameter, in this case the mean. However, we can pick any value
such as 99% or 90%. We can generalize the confidence interval for
<span class="math inline">\(100(1-\alpha)\)</span> as follows:</p>
<p><span class="math display">\[\overline{X} \pm Z_{\alpha/2}\sigma/\sqrt{n}\]</span></p>
<p>In R, we can do this using <code>qnorm()</code> function to get Z-scores associated
with <span class="math inline">\({\alpha/2}\)</span> and <span class="math inline">\({1-\alpha/2}\)</span>. As you can see, the confidence intervals we calculated using CLT are very
similar to the ones we got from bootstrap for the same sample. For bootstrap we got <span class="math inline">\([19.21, 21.989]\)</span> and for the CLT based estimate we got <span class="math inline">\([19.23638, 22.00819]\)</span>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1">alpha=<span class="fl">0.05</span></a>
<a class="sourceLine" id="cb32-2" title="2">sd=<span class="dv">5</span></a>
<a class="sourceLine" id="cb32-3" title="3">n=<span class="dv">50</span></a>
<a class="sourceLine" id="cb32-4" title="4"><span class="kw">mean</span>(sample1)<span class="op">+</span><span class="kw">qnorm</span>(<span class="kw">c</span>(alpha<span class="op">/</span><span class="dv">2</span>,<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>))<span class="op">*</span>sd<span class="op">/</span><span class="kw">sqrt</span>(n)</a></code></pre></div>
<pre><code>## [1] 19.24 22.01</code></pre>
<p>The good thing about CLT as long as the sample size is large regardless of
the population distribution, the distribution of sample means drawn from
that population will always be normal. Here we are repeatedly
drawing samples 1000 times with sample size <span class="math inline">\(n\)</span>=10,30, and 100 from a bimodal,
exponential and a uniform distribution and we are getting sample mean distributions
following normal distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-19"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-19-1.png" alt="Sample means are normally distributed regardless of the population distribution they are drawn from." width="672" />
<p class="caption">
FIGURE 4.7: Sample means are normally distributed regardless of the population distribution they are drawn from.
</p>
</div>
<p>However, we should note that how we constructed the confidence interval
using standard normal distribution, <span class="math inline">\(N(0,1)\)</span>, only works when the when we know the
population standard deviation. In reality, we usually have only access
to a sample and have no idea about the population standard deviation. If
this is the case we should use estimate the standard deviation using
sample standard deviation and use something called <em>t distribution</em> instead
of standard normal distribution in our interval calculation. Our confidence interval becomes
<span class="math inline">\(\overline{X} \pm t_{\alpha/2}s/\sqrt{n}\)</span>, with t distribution
parameter <span class="math inline">\(d.f=n-1\)</span>, since now the following quantity is t distributed <span class="math inline">\(\frac{\overline{X}-\mu}{s/\sqrt{n}}\)</span> instead of standard normal distribution.</p>
The t distribution is similar to standard normal distribution has mean 0 but its spread is larger than the normal distribution
especially when sample size is small, and has one parameter <span class="math inline">\(v\)</span> for
the degrees of freedom, which is <span class="math inline">\(n-1\)</span> in this case. Degrees of freedom
is simply number of data points minus number of parameters estimated. Here
we are estimating the mean from the data and the distribution is for the means, therefore degrees of freedom is <span class="math inline">\(n-1\)</span>.
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-20"></span>
<img src="compgenomrReloaded_files/figure-html/unnamed-chunk-20-1.png" alt="Normal distribution and t distribution with different degrees of freedom. With increasing degrees of freedom, t distribution approximates the normal distribution better." width="60%" />
<p class="caption">
FIGURE 4.8: Normal distribution and t distribution with different degrees of freedom. With increasing degrees of freedom, t distribution approximates the normal distribution better.
</p>
</div>
</div>
</div>
<p style="text-align: center;">
<a href="4-stats.html"><button class="btn btn-default">Previous</button></a>
<a href="4-2-how-to-test-for-differences-between-samples.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
